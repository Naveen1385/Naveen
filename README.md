# ğŸ¤– Autonomous Vehicles & Robotics

This repository showcases my work and experiments in the field of **Autonomous Vehicles** and **Robotics**, combining intelligent systems, computer vision, and real-time automation to build machines that perceive, decide, and act independently.

---

## ğŸ“Œ Features

- ğŸš— **Autonomous navigation** using sensors and AI (LIDAR, GPS, Camera)
- ğŸ§  **Obstacle detection and avoidance** using computer vision and ultrasonic sensing
- ğŸ—º **SLAM & path planning** for unknown environments
- âš™ï¸ **Real-time control** of motors and actuators via feedback loops
- ğŸ“Š **Data logging** for performance and analysis
- ğŸ”„ Scalable to indoor robots, smart cars, and drone systems

---

## ğŸ› ï¸ Technologies Used

- **Python / C++**
- **OpenCV / ROS (Robot Operating System)**
- **YOLO / TensorFlow / PyTorch** (for object detection and decision making)
- **Arduino / Raspberry Pi / Jetson Nano**
- **LIDAR / IMU / Ultrasonic Sensors / Cameras**
- **Gazebo / RViz / CARLA** (for simulation and testing)
- **Flask / MQTT** (optional: for dashboard/API and communication)

---

## ğŸ§  How It Works

1. **Perception**: Sensors capture real-world data (images, distance, orientation).
2. **Processing**: AI and CV algorithms interpret the environment.
3. **Planning**: The system maps surroundings and plans safe paths.
4. **Control**: Commands are sent to motors and actuators for movement.
5. **Loop**: The process repeats in real time, constantly adjusting to new inputs.

---

## ğŸš€ Sample Projects

| Project | Description |
|--------|-------------|
| **AutoRoboCar** | A Raspberry Pi-based vehicle that avoids obstacles and navigates autonomously |
| **LIDAR-SLAM-Bot** | A robot using 2D LIDAR and SLAM for indoor mapping |
| **Traffic-Aware Nav** | Uses real-time traffic data and object detection for adaptive routing |
| **VisionBot** | Line-following and object-detecting robot using OpenCV and deep learning |